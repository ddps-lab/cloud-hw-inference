{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Inferentia inference on Amazon EC2 Inf1 instance\n",
    "This example demonstrates AWS Inferentia inference with TensorFlow and AWS Neuron SDK compiler and runtime\n",
    "\n",
    "This example was tested on Amazon EC2 `inf1.xlarge` the following AWS Deep Learning AMI: \n",
    "`Deep Learning AMI (Ubuntu 18.04) Version 35.0`\n",
    "\n",
    "Run this notebook using the following conda environment:\n",
    "`aws_neuron_tensorflow_p36`\n",
    "\n",
    "Prepare your imagenet validation TFRecord files using the following helper script:\n",
    "https://github.com/tensorflow/models/blob/archive/research/inception/inception/data/download_and_preprocess_imagenet.sh\n",
    "\n",
    "Save it to `/home/ubuntu/datasets/` or update the dataset location in the `get_dataset()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "!/opt/aws/neuron/bin/neuron-cli reset\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.neuron as tfn\n",
    "import tensorflow.compat.v1.keras as keras\n",
    "from tensorflow.keras.applications import ( \n",
    "    xception,\n",
    "    vgg16,\n",
    "    vgg19,\n",
    "    resnet,\n",
    "    resnet50,\n",
    "    resnet_v2,\n",
    "    inception_v3,\n",
    "    inception_resnet_v2,\n",
    "    mobilenet,\n",
    "    densenet,\n",
    "    nasnet,\n",
    "    mobilenet_v2\n",
    ")\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from concurrent import futures\n",
    "from itertools import compress\n",
    "\n",
    "models = {\n",
    "    'xception':xception,\n",
    "    'vgg16':vgg16,\n",
    "    'vgg19':vgg19,\n",
    "    'resnet50':resnet50,\n",
    "    'resnet101':resnet,\n",
    "    'resnet152':resnet,\n",
    "    'resnet50_v2':resnet_v2,\n",
    "    'resnet101_v2':resnet_v2,\n",
    "    'resnet152_v2':resnet_v2,\n",
    "#     'resnext50':resnext,\n",
    "#     'resnext101':resnext,\n",
    "    'inception_v3':inception_v3,\n",
    "    'inception_resnet_v2':inception_resnet_v2,\n",
    "    'mobilenet':mobilenet,\n",
    "    'densenet121':densenet,\n",
    "    'densenet169':densenet,\n",
    "    'densenet201':densenet,\n",
    "    'nasnetlarge':nasnet,\n",
    "    'nasnetmobile':nasnet,\n",
    "    'mobilenet_v2':mobilenet_v2\n",
    "}\n",
    "\n",
    "models_detail = {\n",
    "#     'xception':xception.Xception(weights='imagenet',include_top=False),\n",
    "#     'vgg16':vgg16.VGG16(weights='imagenet'),\n",
    "#     'vgg19':vgg19.VGG19(weights='imagenet'),\n",
    "#     'resnet50':resnet.ResNet50(weights='imagenet'),\n",
    "#     'resnet101':resnet.ResNet101(weights='imagenet'),\n",
    "#     'resnet152':resnet.ResNet152(weights='imagenet'),\n",
    "#     'resnet50_v2':resnet_v2.ResNet50V2(weights='imagenet'),\n",
    "#     'resnet101_v2':resnet_v2.ResNet101V2(weights='imagenet'),\n",
    "#     'resnet152_v2':resnet_v2.ResNet152V2(weights='imagenet'),\n",
    "#     'resnext50':resnext.ResNeXt50(weights='imagenet'),\n",
    "#     'resnext101':resnext.ResNeXt101(weights='imagenet'),\n",
    "#     'inception_v3':inception_v3.InceptionV3(weights='imagenet',include_top=False),\n",
    "#     'inception_resnet_v2':inception_resnet_v2.InceptionResNetV2(weights='imagenet'),\n",
    "#     'mobilenet':mobilenet.MobileNet(weights='imagenet'),\n",
    "#     'densenet121':densenet.DenseNet121(weights='imagenet'),\n",
    "#     'densenet169':densenet.DenseNet169(weights='imagenet'),\n",
    "#     'densenet201':densenet.DenseNet201(weights='imagenet'),\n",
    "#     'nasnetlarge':nasnet.NASNetLarge(weights='imagenet'),\n",
    "#     'nasnetmobile':nasnet.NASNetMobile(weights='imagenet'),\n",
    "#     'mobilenet_v2':mobilenet_v2.MobileNetV2(weights='imagenet')\n",
    "}\n",
    "\n",
    "print('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50 FP32 saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export SavedModel\n",
    "# model_type = 'resnet50'\n",
    "\n",
    "# saved_model_dir = f'{model_type}_saved_model'\n",
    "# shutil.rmtree(saved_model_dir, ignore_errors=True)\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "# model = ResNet50(weights='imagenet')\n",
    "# tf.saved_model.simple_save(session = keras.backend.get_session(),\n",
    "#                            export_dir = saved_model_dir,\n",
    "#                            inputs = {'input_1:0': model.inputs[0]},\n",
    "#                            outputs = {'probs/Softmax:0': model.outputs[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile models with different batch sizes and cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_inf1_model(saved_model_dir, inf1_model_dir, batch_size=1, num_cores=1, use_static_weights=False):\n",
    "    print(f'-----------batch size: {batch_size}, num cores: {num_cores}----------')\n",
    "    print('Compiling...')\n",
    "    \n",
    "    compiled_model_dir = f'{model_type}_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "    inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "    shutil.rmtree(inf1_compiled_model_dir, ignore_errors=True)\n",
    "\n",
    "    example_input = np.zeros([batch_size,224,224,3], dtype='float32')\n",
    "\n",
    "    compiler_args = ['--verbose','1', '--neuroncore-pipeline-cores', str(num_cores)]\n",
    "    if use_static_weights:\n",
    "        compiler_args.append('--static-weights')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    compiled_res = tfn.saved_model.compile(model_dir = saved_model_dir,\n",
    "                            model_feed_dict={'input_1:0': example_input},\n",
    "                            new_model_dir = inf1_compiled_model_dir,\n",
    "                            dynamic_batch_size=True,\n",
    "                            compiler_args = compiler_args)\n",
    "    print(f'Compile time: {time.time() - start_time}')\n",
    "    \n",
    "    compile_success = False\n",
    "    perc_on_inf = compiled_res['OnNeuronRatio'] * 100\n",
    "    if perc_on_inf > 50:\n",
    "        compile_success = True\n",
    "            \n",
    "    print(inf1_compiled_model_dir)\n",
    "    print(compiled_res)\n",
    "    print('----------- Done! ----------- \\n')\n",
    "    \n",
    "    return compile_success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `tf.data` to read ImageNet validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_image_record(record):\n",
    "    feature_map = {'image/encoded': tf.io.FixedLenFeature([], tf.string, ''),\n",
    "                  'image/class/label': tf.io.FixedLenFeature([1], tf.int64, -1),\n",
    "                  'image/class/text': tf.io.FixedLenFeature([], tf.string, '')}\n",
    "    obj = tf.io.parse_single_example(serialized=record, features=feature_map)\n",
    "    imgdata = obj['image/encoded']\n",
    "    label = tf.cast(obj['image/class/label'], tf.int32)   \n",
    "    label_text = tf.cast(obj['image/class/text'], tf.string)   \n",
    "    return imgdata, label, label_text\n",
    "\n",
    "def val_preprocessing(record):\n",
    "    imgdata, label, label_text = deserialize_image_record(record)\n",
    "    label -= 1\n",
    "    image = tf.io.decode_jpeg(imgdata, channels=3, \n",
    "                              fancy_upscaling=False, \n",
    "                              dct_method='INTEGER_FAST')\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "    height = tf.cast(shape[0], tf.float32)\n",
    "    width = tf.cast(shape[1], tf.float32)\n",
    "    side = tf.cast(tf.convert_to_tensor(256, dtype=tf.int32), tf.float32)\n",
    "\n",
    "    scale = tf.cond(tf.greater(height, width),\n",
    "                  lambda: side / width,\n",
    "                  lambda: side / height)\n",
    "    \n",
    "    new_height = tf.cast(tf.math.rint(height * scale), tf.int32)\n",
    "    new_width = tf.cast(tf.math.rint(width * scale), tf.int32)\n",
    "    \n",
    "    image = tf.image.resize(image, [new_height, new_width], method='bicubic')\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 224, 224)\n",
    "    \n",
    "    image = models[model_type].preprocess_input(image)\n",
    "    \n",
    "    return image, label, label_text\n",
    "\n",
    "def get_dataset(batch_size, use_cache=False):\n",
    "    data_dir = '/home/ubuntu/datasets/images-1000/*'\n",
    "    files = tf.io.gfile.glob(os.path.join(data_dir))\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    \n",
    "    dataset = dataset.map(map_func=val_preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat(count=1)\n",
    "    \n",
    "    if use_cache:\n",
    "        shutil.rmtree('tfdatacache', ignore_errors=True)\n",
    "        os.mkdir('tfdatacache')\n",
    "        dataset = dataset.cache(f'./tfdatacache/imagenet_val')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single AWS Inferentia chip execution\n",
    "* Single core compiled models with automatic data parallel model upto 4 cores\n",
    "* Multi-core compiled models for pipeline execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def cnn_predictor(model_inf1,model_feed_dict):\n",
    "    model_inf1(model_feed_dict)\n",
    "    \n",
    "    \n",
    "def inf1_predict_benchmark_single_threaded(neuron_saved_model_name, batch_size, user_batch_size, num_cores, use_cache=False, warm_up=10):\n",
    "    print(f'Running model {neuron_saved_model_name}, user_batch_size: {user_batch_size}\\n')\n",
    "\n",
    "    model_inf1 = tf.contrib.predictor.from_saved_model(neuron_saved_model_name)\n",
    "    os.environ['NEURONCORE_GROUP_SIZES'] = '8x1'\n",
    "    first_iter_time = 0\n",
    "    iter_times = []\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    display_threshold = 0\n",
    "    warm_up = 10\n",
    "\n",
    "    ds = get_dataset(user_batch_size, use_cache)\n",
    "\n",
    "    ds_iter = ds.make_initializable_iterator()\n",
    "    ds_next = ds_iter.get_next()\n",
    "    ds_init_op = ds_iter.initializer\n",
    "   \n",
    "    with tf.Session() as sess:\n",
    "        if use_cache:\n",
    "            sess.run(ds_init_op)\n",
    "            print('\\nCaching dataset ...')\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                while True:\n",
    "                    (validation_ds,label,_) = sess.run(ds_next)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "            print(f'Caching finished: {time.time()-start_time} sec')  \n",
    "\n",
    "        try:\n",
    "#              with futures.ThreadPoolExecutor(8) as exe:\n",
    "                sess.run(ds_init_op)\n",
    "                counter = 0\n",
    "\n",
    "                total_datas = 1000\n",
    "                display_every = 100\n",
    "                display_threshold = display_every\n",
    "\n",
    "                ipname = list(model_inf1.feed_tensors.keys())[0]\n",
    "                resname = list(model_inf1.fetch_tensors.keys())[0]\n",
    "\n",
    "                walltime_start = time.time()\n",
    "                warmup_time = []\n",
    "                extend_time = []\n",
    "                while True:\n",
    "                    sess_start = time.time()\n",
    "                    (validation_ds,batch_labels,_) = sess.run(ds_next)\n",
    "\n",
    "                    model_feed_dict={ipname: validation_ds}\n",
    "    #                 warmup_start = time.time()\n",
    "    #                 if counter == 0:\n",
    "    #                     for i in range(warm_up):\n",
    "    #                         _ = model_inf1(model_feed_dict);                    \n",
    "    #                 warmup_time.append(time.time() - warmup_start)\n",
    "                    start_time =time.time()\n",
    "#                     exe.submit(cnn_predictor,model_inf1,model_feed_dict)\n",
    "                    cnn_predictor(model_inf1,model_feed_dict)\n",
    "                    if counter == 0:\n",
    "                        first_iter_time = time.time() - start_time\n",
    "                    else:\n",
    "                        iter_times.append(time.time() - start_time)\n",
    "\n",
    "                    actual_labels.extend(label for label_list in batch_labels for label in label_list)\n",
    "\n",
    "                    if counter*user_batch_size >= display_threshold:\n",
    "                        print(f'Images {counter*user_batch_size}/{total_datas}. Average i/s {np.mean(user_batch_size/np.array(iter_times[-display_every:]))}')\n",
    "                        display_threshold+=display_every\n",
    "\n",
    "                    counter+=1\n",
    "                    \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "#     acc_inf1 = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "    iter_times = np.array(iter_times)\n",
    "    \n",
    "    results = pd.DataFrame(columns = [f'inf1_compiled_batch_size_{batch_size}_compiled_cores_{num_cores}'])\n",
    "    results.loc['compiled_batch_size']     = [batch_size]\n",
    "    results.loc['user_batch_size']         = [user_batch_size]\n",
    "#     results.loc['accuracy']                = [acc_inf1]\n",
    "    results.loc['first_prediction_time']   = [first_iter_time]\n",
    "    results.loc['average_prediction_time'] = [np.mean(iter_times)]\n",
    "    results.loc['wall_time']               = [time.time() - walltime_start]\n",
    "    display(results.T)\n",
    "#     shutil.rmtree(neuron_saved_model_name, ignore_errors=True)\n",
    "\n",
    "\n",
    "    return results, iter_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: xception_inf1_saved_models/xception_batch_64_inf1_cores_1\n",
      "Running model xception_inf1_saved_models/xception_batch_64_inf1_cores_1, user_batch_size: 16384\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_type = 'xception'\n",
    "# https://github.com/tensorflow/tensorflow/issues/29931\n",
    "temp = tf.zeros([8, 224, 224, 3])\n",
    "_ = models[model_type].preprocess_input(temp)\n",
    "\n",
    "# testing batch size\n",
    "batch_list = [64]\n",
    "num_of_cores = [1]\n",
    "user_batchs = [256]\n",
    "inf1_model_dir = f'{model_type}_inf1_saved_models'\n",
    "\n",
    "for user_batch in user_batchs:\n",
    "    iter_ds = pd.DataFrame()\n",
    "    results = pd.DataFrame()\n",
    "    for batch_size in batch_list:\n",
    "        for num_cores in num_of_cores:\n",
    "            opt ={'batch_size': batch_size, 'num_cores': num_of_cores}\n",
    "            compiled_model_dir = f'{model_type}_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "            inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "\n",
    "            print(f'inf1_compiled_model_dir: {inf1_compiled_model_dir}')\n",
    "            col_name = lambda opt: f'inf1_{batch_size}_multicores_{num_cores}'\n",
    "\n",
    "            res, iter_times = inf1_predict_benchmark_single_threaded(inf1_compiled_model_dir,\n",
    "                                                                             batch_size = batch_size,\n",
    "                                                                             user_batch_size = batch_size*user_batch,\n",
    "                                                                             num_cores = num_cores,\n",
    "                                                                             use_cache=False, \n",
    "                                                                             warm_up=10)\n",
    "\n",
    "        iter_ds = pd.concat([iter_ds, pd.DataFrame(iter_times, columns=[col_name(opt)])], axis=1)\n",
    "        results = pd.concat([results, res], axis=1)\n",
    "    display(results)\n",
    "    results.to_csv(f'{model_type}_batch_size_{batch_size}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuron_tensorflow_p36_2",
   "language": "python",
   "name": "aws_neuron_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
