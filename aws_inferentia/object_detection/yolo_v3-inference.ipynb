{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate YOLO v3 on Inferentia\n",
    "## Note: this tutorial runs on tensorflow-neuron 1.x only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This tutorial walks through compiling and evaluating YOLO v3 model on Inferentia using the AWS Neuron SDK.\n",
    "\n",
    "\n",
    "In this tutorial we provide two main sections:\n",
    "\n",
    "1. Download Dataset and Generate Pretrained SavedModel\n",
    "\n",
    "2. Compile the YOLO v3 model.\n",
    "\n",
    "3. Deploy the same compiled model.\n",
    "\n",
    "Before running the following verify this Jupyter notebook is running “conda_aws_neuron_tensorflow_p36” kernel. You can select the Kernel from the “Kernel -> Change Kernel” option on the top of this Jupyter notebook page.\n",
    "\n",
    "Instructions of how to setup Neuron Tensorflow environment and run the tutorial as a Jupyter notebook are available in the Tutorial main page [Tensorflow-YOLO_v3 Tutorial](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/neuron-frameworks/tensorflow-neuron/tutorials/yolo_v3_demo/yolo_v3_demo.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo requires the following pip packages:\n",
    "\n",
    "`pillow matplotlib pycocotools`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model on Inferentia\n",
    "## Part 3:Evaluate Model Quality after Compilation\n",
    "\n",
    "### Define evaluation functions\n",
    "We first define some handy helper functions for running evaluation on the COCO 2017 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def cocoapi_eval(jsonfile,\n",
    "                 style,\n",
    "                 coco_gt=None,\n",
    "                 anno_file=None,\n",
    "                 max_dets=(100, 300, 1000)):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        jsonfile: Evaluation json file, eg: bbox.json, mask.json.\n",
    "        style: COCOeval style, can be `bbox` , `segm` and `proposal`.\n",
    "        coco_gt: Whether to load COCOAPI through anno_file,\n",
    "                 eg: coco_gt = COCO(anno_file)\n",
    "        anno_file: COCO annotations file.\n",
    "        max_dets: COCO evaluation maxDets.\n",
    "    \"\"\"\n",
    "    assert coco_gt is not None or anno_file is not None\n",
    "\n",
    "    if coco_gt is None:\n",
    "        coco_gt = COCO(anno_file)\n",
    "    print(\"Start evaluate...\")\n",
    "    coco_dt = coco_gt.loadRes(jsonfile)\n",
    "    if style == 'proposal':\n",
    "        coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "        coco_eval.params.useCats = 0\n",
    "        coco_eval.params.maxDets = list(max_dets)\n",
    "    else:\n",
    "        coco_eval = COCOeval(coco_gt, coco_dt, style)\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "    return coco_eval.stats\n",
    "\n",
    "\n",
    "def bbox_eval(anno_file, bbox_list):\n",
    "    coco_gt = COCO(anno_file)\n",
    "\n",
    "    outfile = 'bbox_detections.json'\n",
    "    print('Generating json file...')\n",
    "    with open(outfile, 'w') as f:\n",
    "        json.dump(bbox_list, f)\n",
    "\n",
    "    map_stats = cocoapi_eval(outfile, 'bbox', coco_gt=coco_gt)\n",
    "    return map_stats\n",
    "\n",
    "\n",
    "def get_image_as_bytes(images, eval_pre_path, user_batch_size):\n",
    "    batch_im_id_list = []\n",
    "    batch_im_name_list = []\n",
    "    batch_img_bytes_list = []\n",
    "    n = len(images)\n",
    "    batch_im_id = []\n",
    "    batch_im_name = []\n",
    "    batch_img_bytes = []\n",
    "    for i, im in enumerate(images):\n",
    "        im_id = im['id']\n",
    "        file_name = im['file_name']\n",
    "        if i % user_batch_size == 0 and i != 0:\n",
    "            batch_im_id_list.append(batch_im_id)\n",
    "            batch_im_name_list.append(batch_im_name)\n",
    "            batch_img_bytes_list.append(batch_img_bytes)\n",
    "            batch_im_id = []\n",
    "            batch_im_name = []\n",
    "            batch_img_bytes = []\n",
    "        batch_im_id.append(im_id)\n",
    "        batch_im_name.append(file_name)\n",
    "\n",
    "        with open(os.path.join(eval_pre_path, file_name), 'rb') as f:\n",
    "            batch_img_bytes.append(f.read())\n",
    "    return batch_im_id_list, batch_im_name_list, batch_img_bytes_list\n",
    "\n",
    "\n",
    "def analyze_bbox(results, batch_im_id, _clsid2catid):\n",
    "    bbox_list = []\n",
    "    k = 0\n",
    "    for boxes, scores, classes in zip(results['boxes'], results['scores'], results['classes']):\n",
    "        if boxes is not None:\n",
    "            im_id = batch_im_id[k]\n",
    "            n = len(boxes)\n",
    "            for p in range(n):\n",
    "                clsid = classes[p]\n",
    "                score = scores[p]\n",
    "                xmin, ymin, xmax, ymax = boxes[p]\n",
    "                catid = (_clsid2catid[int(clsid)])\n",
    "                w = xmax - xmin + 1\n",
    "                h = ymax - ymin + 1\n",
    "\n",
    "                bbox = [xmin, ymin, w, h]\n",
    "                # Round to the nearest 10th to avoid huge file sizes, as COCO suggests\n",
    "                bbox = [round(float(x) * 10) / 10 for x in bbox]\n",
    "                bbox_res = {\n",
    "                    'image_id': im_id,\n",
    "                    'category_id': catid,\n",
    "                    'bbox': bbox,\n",
    "                    'score': float(score),\n",
    "                }\n",
    "                bbox_list.append(bbox_res)\n",
    "        k += 1\n",
    "    return bbox_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the actual evaluation loop. To fully utilize all four cores on one Inferentia, the optimal setup is to run multi-threaded inference using a `ThreadPoolExecutor`. The following cell is a multi-threaded adaptation of the evaluation routine at https://github.com/miemie2013/Keras-YOLOv4/blob/910c4c6f7265f5828fceed0f784496a0b46516bf/tools/cocotools.py#L97."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "\n",
    "def evaluate(yolo_predictor, images, eval_pre_path, anno_file, eval_batch_size, _clsid2catid, user_batch_size, num_cores):\n",
    "    batch_im_id_list, batch_im_name_list, batch_img_bytes_list = get_image_as_bytes(images, eval_pre_path, user_batch_size)\n",
    "    walltime_start = time.time()\n",
    "    # warm up\n",
    "#     yolo_predictor({'image': np.array(batch_img_bytes_list[0], dtype=object)})\n",
    "\n",
    "#     with futures.ThreadPoolExecutor(4) as exe:\n",
    "#         fut_im_list = []\n",
    "#         fut_list = []\n",
    "#         start_time = time.time()\n",
    "#         for batch_im_id, batch_im_name, batch_img_bytes in zip(batch_im_id_list, batch_im_name_list, batch_img_bytes_list):\n",
    "#             if len(batch_img_bytes) != eval_batch_size:\n",
    "#                 continue\n",
    "#             fut = exe.submit(yolo_predictor, {'image': np.array(batch_img_bytes, dtype=object)})\n",
    "#             fut_im_list.append((batch_im_id, batch_im_name))\n",
    "#             fut_list.append(fut)\n",
    "#         bbox_list = []\n",
    "#         count = 0\n",
    "#         for (batch_im_id, batch_im_name), fut in zip(fut_im_list, fut_list):\n",
    "#             results = fut.result()\n",
    "#             bbox_list.extend(analyze_bbox(results, batch_im_id, _clsid2catid))\n",
    "#             for _ in batch_im_id:\n",
    "#                 count += 1\n",
    "#                 if count % 100 == 0:\n",
    "#                     print('Test iter {}'.format(count))\n",
    "#         print('==================== Performance Measurement ====================')\n",
    "#         print('Finished inference on {} images in {} seconds'.format(len(images), time.time() - start_time))\n",
    "#         print('=================================================================')\n",
    "#     # start evaluation\n",
    "#     box_ap_stats = bbox_eval(anno_file, bbox_list)\n",
    "    iter_times = []\n",
    "    counter = 0\n",
    "    first_iter_time = 0\n",
    "    fut_im_list = []\n",
    "    fut_list = []\n",
    "    for batch_im_id, batch_im_name, batch_img_bytes in zip(batch_im_id_list, batch_im_name_list, batch_img_bytes_list):\n",
    "        if len(batch_img_bytes) != user_batch_size:\n",
    "            continue\n",
    "        iter_start = time.time()\n",
    "        fut = yolo_predictor({'image': np.array(batch_img_bytes, dtype=object)})\n",
    "        fut_im_list.append((batch_im_id, batch_im_name))\n",
    "        fut_list.append(fut)\n",
    "        if counter == 0:\n",
    "            first_iter_time = time.time() - iter_start\n",
    "        else:\n",
    "            iter_times.append(time.time() - iter_start)\n",
    "        counter +=1\n",
    "    bbox_list = []\n",
    "    counter = 0\n",
    "    for (batch_im_id, batch_im_name), fut in zip(fut_im_list, fut_list):\n",
    "        results = fut\n",
    "        bbox_list.extend(analyze_bbox(results, batch_im_id, _clsid2catid))\n",
    "        for _ in batch_im_id:\n",
    "            counter += 1\n",
    "            if counter % 100 == 0:\n",
    "                print('Test iter {}'.format(counter))\n",
    "    \n",
    "    print('==================== Performance Measurement ====================')\n",
    "    print('Finished inference on {} images in {} seconds'.format(len(images), time.time() - walltime_start))\n",
    "    print('=================================================================')\n",
    "    \n",
    "    results = pd.DataFrame(columns = [f'inf1_compiled_batch_size_{eval_batch_size}_compiled_cores_{num_cores}'])\n",
    "    results.loc['compiled_batch_size'] = [eval_batch_size]\n",
    "    results.loc['user_batch_size'] = [user_batch_size]\n",
    "    results.loc['first_prediction_time'] = [first_iter_time]\n",
    "    results.loc['average_prediction_time'] = [np.mean(iter_times)]\n",
    "    results.loc['wall_time'] = [time.time() - walltime_start]\n",
    "    box_ap_stats = bbox_eval(anno_file, bbox_list)\n",
    "    return box_ap_stats, results, iter_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate mean average precision (mAP) score\n",
    "Here is the code to calculate mAP scores of the YOLO v3 model. The expected mAP score is around 0.328 if we use the pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: yolo_v3_coco_inf1_saved_models/yolo_v3_coco_batch_1_inf1_cores_1\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/predictor/saved_model_predictor.py:153: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Max scatter index must be < array size (1 vs. 1)\n\t [[node Postprocessor/map/TensorArrayUnstack_3/TensorArrayScatter/TensorArrayScatterV3 (defined at /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'Postprocessor/map/TensorArrayUnstack_3/TensorArrayScatter/TensorArrayScatterV3':\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 619, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n    return callable(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n    return callable(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n    return callable(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 538, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n    return callable(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-1f0565959362>\", line 34, in <module>\n    yolo_pred = tf.contrib.predictor.from_saved_model(inf1_compiled_model_dir)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/predictor/predictor_factories.py\", line 153, in from_saved_model\n    config=config)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/predictor/saved_model_predictor.py\", line 153, in __init__\n    loader.load(self._session, tags.split(','), export_dir)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/loader_impl.py\", line 269, in load\n    return loader.load(sess, tags, import_scope, **saver_kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/loader_impl.py\", line 422, in load\n    **saver_kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/loader_impl.py\", line 352, in load_graph\n    meta_graph_def, import_scope=import_scope, **saver_kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py\", line 1477, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/meta_graph.py\", line 809, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 405, in import_graph_def\n    producer_op_list=producer_op_list)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 517, in _import_graph_def_internal\n    _ProcessNewOps(graph)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 243, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3561, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3561, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3451, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Max scatter index must be < array size (1 vs. 1)\n\t [[{{node Postprocessor/map/TensorArrayUnstack_3/TensorArrayScatter/TensorArrayScatterV3}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1f0565959362>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m                                                \u001b[0mclsid2catid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                                                \u001b[0meval_batch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0muser_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                                                num_cores)\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0miter_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-98834575a79e>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(yolo_predictor, images, eval_pre_path, anno_file, eval_batch_size, _clsid2catid, user_batch_size, num_cores)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0miter_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mfut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myolo_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_img_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mfut_im_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_im_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_im_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mfut_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/predictor/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Max scatter index must be < array size (1 vs. 1)\n\t [[node Postprocessor/map/TensorArrayUnstack_3/TensorArrayScatter/TensorArrayScatterV3 (defined at /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'Postprocessor/map/TensorArrayUnstack_3/TensorArrayScatter/TensorArrayScatterV3':\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 619, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n    return callable(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n    return callable(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n    return callable(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 538, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n    return callable(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-1f0565959362>\", line 34, in <module>\n    yolo_pred = tf.contrib.predictor.from_saved_model(inf1_compiled_model_dir)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/predictor/predictor_factories.py\", line 153, in from_saved_model\n    config=config)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/predictor/saved_model_predictor.py\", line 153, in __init__\n    loader.load(self._session, tags.split(','), export_dir)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/loader_impl.py\", line 269, in load\n    return loader.load(sess, tags, import_scope, **saver_kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/loader_impl.py\", line 422, in load\n    **saver_kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/loader_impl.py\", line 352, in load_graph\n    meta_graph_def, import_scope=import_scope, **saver_kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py\", line 1477, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/meta_graph.py\", line 809, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 405, in import_graph_def\n    producer_op_list=producer_op_list)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 517, in _import_graph_def_internal\n    _ProcessNewOps(graph)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 243, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3561, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3561, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3451, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_coco_root = './val2017'\n",
    "val_annotate = './annotations/instances_val2017.json'\n",
    "clsid2catid = {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 13, 12: 14, 13: 15, 14: 16,\n",
    "               15: 17, 16: 18, 17: 19, 18: 20, 19: 21, 20: 22, 21: 23, 22: 24, 23: 25, 24: 27, 25: 28, 26: 31,\n",
    "               27: 32, 28: 33, 29: 34, 30: 35, 31: 36, 32: 37, 33: 38, 34: 39, 35: 40, 36: 41, 37: 42, 38: 43,\n",
    "               39: 44, 40: 46, 41: 47, 42: 48, 43: 49, 44: 50, 45: 51, 46: 52, 47: 53, 48: 54, 49: 55, 50: 56,\n",
    "               51: 57, 52: 58, 53: 59, 54: 60, 55: 61, 56: 62, 57: 63, 58: 64, 59: 65, 60: 67, 61: 70, 62: 72,\n",
    "               63: 73, 64: 74, 65: 75, 66: 76, 67: 77, 68: 78, 69: 79, 70: 80, 71: 81, 72: 82, 73: 84, 74: 85,\n",
    "               75: 86, 76: 87, 77: 88, 78: 89, 79: 90}\n",
    "\n",
    "model_type = 'yolo_v3_coco'\n",
    "\n",
    "batch_list = [1,2,4,8]\n",
    "num_of_cores = [1]\n",
    "user_batchs = [2,4,8,16,32,64]\n",
    "inf1_model_dir = f'{model_type}_inf1_saved_models'\n",
    "for user_batch in user_batchs:\n",
    "    iter_ds = pd.DataFrame()\n",
    "    results = pd.DataFrame()\n",
    "    for eval_batch_size in batch_list:\n",
    "        for num_cores in num_of_cores:\n",
    "            opt ={'batch_size': eval_batch_size, 'num_cores': num_of_cores}\n",
    "            compiled_model_dir = f'{model_type}_batch_{eval_batch_size}_inf1_cores_{num_cores}'\n",
    "            inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "\n",
    "            print(f'inf1_compiled_model_dir: {inf1_compiled_model_dir}')\n",
    "            col_name = lambda opt: f'inf1_{eval_batch_size}_multicores_{num_cores}'\n",
    "\n",
    "            with open(val_annotate, 'r', encoding='utf-8') as f2:\n",
    "                for line in f2:\n",
    "                    line = line.strip()\n",
    "                    dataset = json.loads(line)\n",
    "                    images = dataset['images']\n",
    "            yolo_pred = tf.contrib.predictor.from_saved_model(inf1_compiled_model_dir)\n",
    "            box_ap, res, iter_times = evaluate(yolo_pred,\n",
    "                                               images,\n",
    "                                               val_coco_root,\n",
    "                                               val_annotate,\n",
    "                                               eval_batch_size,\n",
    "                                               clsid2catid,\n",
    "                                               eval_batch_size * user_batch, \n",
    "                                               num_cores)\n",
    "\n",
    "        iter_ds = pd.concat([iter_ds, pd.DataFrame(iter_times, columns=[col_name(opt)])], axis=1)\n",
    "        results = pd.concat([results, res], axis=1)\n",
    "    display(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuron_tensorflow_p36_2",
   "language": "python",
   "name": "aws_neuron_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
