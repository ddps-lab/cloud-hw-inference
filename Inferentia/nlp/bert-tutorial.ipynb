{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "changing-baking",
   "metadata": {},
   "source": [
    "# Compiling and Deploying Pretrained HuggingFace Pipelines distilBERT with Tensorflow2 Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-renewal",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-amateur",
   "metadata": {},
   "source": [
    "In this tutorial you will compile and deploy distilBERT version of HuggingFace ðŸ¤— Transformers BERT for Inferentia. The full list of HuggingFace's pretrained BERT models can be found in the BERT section on this page https://huggingface.co/transformers/pretrained_models.html. you can also read about HuggingFace's pipeline feature here: https://huggingface.co/transformers/main_classes/pipelines.html\n",
    "\n",
    "This Jupyter notebook should be run on an instance which is inf1.6xlarge or larger, but in real life scenario the compilation should be done on a compute instance and the deployment on inf1 instance to save costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-tourist",
   "metadata": {},
   "source": [
    "### Setting up your environment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-tyler",
   "metadata": {},
   "source": [
    "To run this tutorial, please make sure you deactivate any existing TensorFlow conda environments you already using. Install TensorFlow 2.x by following the instructions at [TensorFlow Tutorial Setup Guide](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/neuron-frameworks/tensorflow-neuron/tutorials/tensorflow-tutorial-setup.html#tensorflow-tutorial-setup).\n",
    "\n",
    "After following the Setup Guide, you need to change your kernel to ```Python (Neuron TensorFlow 2)``` by clicking Kerenel->Change Kernel->```Python (Neuron TensorFlow 2)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-finnish",
   "metadata": {},
   "source": [
    "Now you can install TensorFlow Neuron 2.x, HuggingFace transformers, and HuggingFace datasets dependencies here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "electronic-probe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: transformers in /home/ec2-user/.local/lib/python3.7/site-packages (4.20.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.7/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib64/python3.7/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/.local/lib/python3.7/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/.local/lib/python3.7/site-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ec2-user/.local/lib/python3.7/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/ec2-user/.local/lib/python3.7/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/.local/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->transformers) (1.26.9)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/site-packages (7.7.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (5.3.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (7.32.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (6.13.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (1.1.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (3.6.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\n",
      "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib64/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib64/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib64/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (2.12.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.29)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (62.1.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets) (2.15.3)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets) (4.10.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.4.11)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (4.11.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib64/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/.local/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (3.7.4.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (21.4.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: pyzmq>=22.3 in /usr/local/lib64/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.14.1)\n",
      "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.5.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.3)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging->ipykernel>=4.5.1->ipywidgets) (3.0.8)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/site-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (3.8.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib64/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.11.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/.local/lib/python3.7/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib64/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib64/python3.7/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.7/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adjacent-avatar",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-03 03:25:58.863780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-07-03 03:25:59.860352: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-03 03:25:59.982273: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-07-03 03:25:59.982312: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-49-69.us-west-2.compute.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-07-03 03:26:00.046481: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
    "import tensorflow as tf\n",
    "import tensorflow.neuron as tfn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-forwarding",
   "metadata": {},
   "source": [
    "### Compile the model into an AWS Neuron Optimized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "great-citation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.6728695034980774},\n",
       " {'label': 'LABEL_0', 'score': 0.6818313598632812}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the huggingface pipeline for sentiment analysis\n",
    "#this model tries to determine of the input text has a positive\n",
    "#or a negative sentiment.\n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "pipe = pipeline('sentiment-analysis', model=model_name, framework='tf')\n",
    "\n",
    "#pipelines are extremely easy to use as they do all the tokenization,\n",
    "#inference and output interpretation for you.\n",
    "pipe(['I love pipelines, they are very easy to use!', 'this string makes it batch size two'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-component",
   "metadata": {},
   "source": [
    "As yo've seen above, Huggingface's pipline feature is a great wrapper for running inference on their models. It takes care of the tokenization of the string inputs. Then feeds that tokenized input to the model. Finally it interprets the outputs of the model and formats them in a way that is very human readable. Our goal will be to compile the underlying model inside the pipeline as well as make some edits to the tokenizer. The reason you need to edit the tokenizer is to make sure that you have a standard sequence length (in this case 128) as neuron only accepts static input shapes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-broadway",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/cloud-hw-inference/Inferentia/tensorflow_venv2.5.3/lib64/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-03 03:26:15.419428: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-07-03 03:26:15.419574: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-07-03 03:26:15.439147: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2999995000 Hz\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"acc\"])\n",
    "original_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "def wrapper_function(*args, **kwargs):\n",
    "    kwargs['padding'] = 'max_length'\n",
    "    #this is the key line here to set a static input shape\n",
    "    #so that all inputs are set to a len of 128\n",
    "    kwargs['max_length'] = 128 \n",
    "    kwargs['truncation'] = True\n",
    "    kwargs['return_tensors'] = 'tf'\n",
    "    return original_tokenizer(*args, **kwargs)\n",
    "\n",
    "#Our example data!\n",
    "string_inputs = [\n",
    "    'I love to eat pizza!',\n",
    "    'I am sorry. I really want to like it, but I just can not stand sushi.',\n",
    "    'I really do not want to type out 128 strings to create batch 128 data.',\n",
    "    'Ah! Multiplying this list by 32 would be a great solution!',\n",
    "]\n",
    "string_inputs = string_inputs * 32\n",
    "\n",
    "\n",
    "example_inputs = wrapper_function(string_inputs)\n",
    "example_inputs_list = [example_inputs['input_ids'], example_inputs['attention_mask']]\n",
    "\n",
    "# example_inputs['input_ids'], example_inputs['attention_mask']\n",
    "#compile the model by calling tfn.trace by passing in the underlying model\n",
    "#and the example inputs generated by our updated tokenizer\n",
    "def subgraph_builder_function(node):\n",
    "    return node.op == 'MatMul'\n",
    "\n",
    "neuron_model = tfn.trace(model, example_inputs_list,\n",
    "                         subgraph_builder_function=subgraph_builder_function)\n",
    "neuron_model.save('./bert_based-uncased-neuron')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65663e26",
   "metadata": {},
   "source": [
    "### Why use batch size 128?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b3c325",
   "metadata": {},
   "source": [
    "You'll notice that in the above example we passed a two tensors of shape 128 (the batch size) x 128 (the sequence length) in this function call ```tfn.trace(pipe.model, example_inputs)```. The example_inputs argument is important to ```tfn.trace``` because it tells the neuron model what to expect (remember that a neuron model needs static input shapes, so example_inputs defines that static input shape). A smaller batch size would also compile, but a large batch size ensures that the neuron hardware will be fed enough data to be as performant as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15a3e3f",
   "metadata": {},
   "source": [
    "### What if my model isn't a Huggingface pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbed4d8",
   "metadata": {},
   "source": [
    "Not to worry! There is no requirement that your model needs to be Huggingface pipeline compatible. The Huggingface pipeline is just a wrapper for an underlying TensorFlow model (in our case ```pipe.model```). As long as you have a TensorFlow 2.x model you can compile it on neuron by calling ```tfn.trace(your_model, example_inputs)```. The processing the input and output to your own model is up to you! Take a look at the example below to see what happens when we call the model without the Huggingface pipeline wrapper as opposed to with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directly call the model\n",
    "neuron_model.save('./bert_based-uncased-neuron')\n",
    "print(example_inputs)\n",
    "print(string_inputs)\n",
    "\n",
    "print(neuron_model(example_inputs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-zoning",
   "metadata": {},
   "source": [
    "### Save your neuron model to disk and avoid recompilation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e867f51",
   "metadata": {},
   "source": [
    "To avoid recompiling the model before every deployment, you can save the neuron model by calling ```model_neuron.save(model_dir)```. This ```save``` method prefers to work on a flat input/output lists and does not work on dictionary input/output - which is what the Huggingface distilBERT expects as input. You can work around this by writing a simple wrapper that takes in an input list instead of a dictionary, compile the wrapped model and save it for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af845f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_inputs_list = [example_inputs['input_ids'], example_inputs['attention_mask']]\n",
    "\n",
    "#compile the wrapped model and save it to disk\n",
    "model_wrapped_traced = tfn.trace(model_wrapped, example_inputs_list)\n",
    "model_wrapped_traced.save('./distilbert_b128')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a113cf0f",
   "metadata": {},
   "source": [
    "### Load the model from disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05260d70",
   "metadata": {},
   "source": [
    "Now you can reload the model by calling ```tf.keras.models.load_model(str : model_directory)```. This model is already compiled and could run inference on neuron, but if you want it to work with our Huggingface pipeline, you have to wrap it again to accept dictionary input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0712501",
   "metadata": {},
   "source": [
    "### Benchmarking the neuron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.warn(\"NEURONCORE_GROUP_SIZES is being deprecated, if your application is using NEURONCORE_GROUP_SIZES please \\\n",
    "see https://awsdocs-neuron.readthedocs-hosted.com/en/latest/release-notes/deprecation.html#announcing-end-of-support-for-neuroncore-group-sizes \\\n",
    "for more details.\", DeprecationWarning)\n",
    "%env NEURONCORE_GROUP_SIZES='4x1'\n",
    "\n",
    "import time\n",
    "\n",
    "#warmup inf\n",
    "neuron_pipe(string_inputs)\n",
    "#benchmark batch 128 neuron model\n",
    "neuron_b128_times = []\n",
    "for i in range(1000):\n",
    "    start = time.time()\n",
    "    outputs = neuron_model(example_inputs)\n",
    "    end = time.time()\n",
    "    neuron_b128_times.append(end - start)\n",
    "    \n",
    "\n",
    "neuron_b128_times = sorted(neuron_b128_times)\n",
    "\n",
    "print(f\"Average throughput for batch 128 neuron model is {128/(sum(neuron_b128_times)/len(neuron_b128_times))} sentences/s.\")\n",
    "print(f\"Peak throughput for batch 128 neuron model is {128/min(neuron_b128_times)} sentences/s.\")\n",
    "print()\n",
    "\n",
    "\n",
    "print(f\"50th percentile latency for batch 128 neuron model is {neuron_b128_times[int(1000*.5)] * 1000} ms.\")\n",
    "print(f\"90th percentile latency for batch 128 neuron model is {neuron_b128_times[int(1000*.9)] * 1000} ms.\")\n",
    "print(f\"95th percentile latency for bacth 128 neuron model is {neuron_b128_times[int(1000*.95)] * 1000} ms.\")\n",
    "print(f\"99th percentile latency for batch 128 neuron model is {neuron_b128_times[int(1000*.99)] * 1000} ms.\")\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e5b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e259a7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_venv2.5.3",
   "language": "python",
   "name": "tensorflow_venv2.5.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
