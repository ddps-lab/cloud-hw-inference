{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Inferentia inference on Amazon EC2 Inf1 instance\n",
    "This example demonstrates AWS Inferentia inference with TensorFlow and AWS Neuron SDK compiler and runtime\n",
    "\n",
    "This example was tested on Amazon EC2 `inf1.xlarge` the following AWS Deep Learning AMI: \n",
    "`Deep Learning AMI (Ubuntu 18.04) Version 35.0`\n",
    "\n",
    "Run this notebook using the following conda environment:\n",
    "`aws_neuron_tensorflow_p36`\n",
    "\n",
    "Prepare your imagenet validation TFRecord files using the following helper script:\n",
    "https://github.com/tensorflow/models/blob/archive/research/inception/inception/data/download_and_preprocess_imagenet.sh\n",
    "\n",
    "Save it to `/home/ubuntu/datasets/` or update the dataset location in the `get_dataset()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 02:02:26.586645: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 02:02:27.506972: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-17 02:02:27.608286: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-11-17 02:02:27.608323: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-61-116.us-west-2.compute.internal): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.neuron as tfn\n",
    "import tensorflow.compat.v1.keras as keras\n",
    "# from tensorflow.keras.applications import ( \n",
    "#     xception,\n",
    "#     vgg16,\n",
    "#     vgg19,\n",
    "#     resnet,\n",
    "#     resnet50,\n",
    "#     resnet_v2,\n",
    "#     inception_v3,\n",
    "#     inception_resnet_v2,\n",
    "#     mobilenet,\n",
    "#     densenet,\n",
    "#     nasnet,\n",
    "#     mobilenet_v2\n",
    "# )\n",
    "# # from keras import backend as K\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# # from concurrent import futures\n",
    "# from itertools import compress\n",
    "\n",
    "\n",
    "# models = {\n",
    "# #     'xception':xception,\n",
    "#     'vgg16':vgg16,\n",
    "# #     'vgg19':vgg19,\n",
    "# #     'resnet50':resnet50,\n",
    "# #     'resnet101':resnet,\n",
    "# #     'resnet152':resnet,\n",
    "# #     'resnet50_v2':resnet_v2,\n",
    "# #     'resnet101_v2':resnet_v2,\n",
    "# #     'resnet152_v2':resnet_v2,\n",
    "# #     'resnext50':resnext,\n",
    "# #     'resnext101':resnext,\n",
    "# #     'inception_v3':inception_v3,\n",
    "# #     'inception_resnet_v2':inception_resnet_v2,\n",
    "# #     'mobilenet':mobilenet,\n",
    "# #     'densenet121':densenet,\n",
    "# #     'densenet169':densenet,\n",
    "# #     'densenet201':densenet,\n",
    "# #     'nasnet':nasnet,\n",
    "# #     'nasnet':nasnet,\n",
    "# #     'mobilenet_v2':mobilenet_v2\n",
    "# }\n",
    "\n",
    "# models_detail = {\n",
    "# #     'xception':xception.Xception(weights='imagenet'),\n",
    "#     'vgg16':vgg16.VGG16(weights='imagenet'),\n",
    "# #     'vgg19':vgg19.VGG19(weights='imagenet'),\n",
    "# #     'resnet50':resnet50.ResNet50(weights='imagenet'),\n",
    "# #     'resnet101':resnet.ResNet101(weights='imagenet'),\n",
    "# #     'resnet152':resnet.ResNet152(weights='imagenet'),\n",
    "# #     'resnet50_v2':resnet_v2.ResNet50V2(weights='imagenet'),\n",
    "# #     'resnet101_v2':resnet_v2.ResNet101V2(weights='imagenet'),\n",
    "# #     'resnet152_v2':resnet_v2.ResNet152V2(weights='imagenet'),\n",
    "# #     'resnext50':resnext.ResNeXt50(weights='imagenet'),\n",
    "# #     'resnext101':resnext.ResNeXt101(weights='imagenet'),\n",
    "# #     'inception_v3':inception_v3.InceptionV3(weights='imagenet'),\n",
    "# #     'inception_resnet_v2':inception_resnet_v2.InceptionResNetV2(weights='imagenet'),\n",
    "# #     'mobilenet':mobilenet.MobileNet(weights='imagenet'),\n",
    "# #     'densenet121':densenet.DenseNet121(weights='imagenet'),\n",
    "# #     'densenet169':densenet.DenseNet169(weights='imagenet'),\n",
    "# #     'densenet201':densenet.DenseNet201(weights='imagenet'),\n",
    "# #     'nasnet':nasnet.NASNetLarge(weights='imagenet'),\n",
    "# #     'nasnet':nasnet.NASNetMobile(weights='imagenet'),\n",
    "# #     'mobilenet_v2':mobilenet_v2.MobileNetV2(weights='imagenet')\n",
    "# }\n",
    "\n",
    "\n",
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = 'vgg16'\n",
    "\n",
    "# # https://github.com/tensorflow/tensorflow/issues/29931\n",
    "# temp = tf.zeros([8, 224, 224, 3])\n",
    "# _ = models[model_type].preprocess_input(temp)\n",
    "\n",
    "# print('test2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50 FP32 saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 02:02:27.683316: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Export SavedModel\n",
    "\n",
    "model_name = 'models/vgg16_conv64'\n",
    "saved_model_dir = f'{model_name}'\n",
    "# shutil.rmtree(saved_model_dir, ignore_errors=True)\n",
    "\n",
    "# model = models_detail[model_type]\n",
    "\n",
    "# model.save(saved_model_dir)\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(saved_model_dir, compile=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile models with different batch sizes and cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_inf1_model(saved_model_dir, inf1_model_dir, batch_size=1, num_cores=1, use_static_weights=False):\n",
    "    print(f'-----------batch size: {batch_size}, num cores: {num_cores}----------')\n",
    "    print('Compiling...')\n",
    "    \n",
    "    compiled_model_dir = f'{model_name}_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "    inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "    shutil.rmtree(inf1_compiled_model_dir, ignore_errors=True)\n",
    "\n",
    "    example_input = np.zeros([batch_size,224,224,3], dtype='float32')\n",
    "    !env NEURON_CC_FLAGS=\"--neuroncore-pipeline-cores=1\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    compiled_model = tfn.trace(model,example_input)\n",
    "    compiled_res = compiled_model.save(inf1_compiled_model_dir)\n",
    "    print(f'Compile time: {time.time() - start_time}')\n",
    "    \n",
    "    compile_success = False\n",
    "#     perc_on_inf = compiled_res['OnNeuronRatio'] * 100\n",
    "#     if perc_on_inf > 50:\n",
    "#         compile_success = True\n",
    "            \n",
    "    print(inf1_compiled_model_dir)\n",
    "    print(compiled_res)\n",
    "    print('----------- Done! ----------- \\n')\n",
    "    \n",
    "    return compile_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 1 core nums 1 compile start\n",
      "-----------batch size: 1, num cores: 1----------\n",
      "Compiling...\n",
      "XDG_SESSION_ID=1\r\n",
      "HOSTNAME=ip-172-31-61-116.us-west-2.compute.internal\r\n",
      "SHELL=/bin/bash\r\n",
      "TERM=xterm-color\r\n",
      "CLICOLOR=1\r\n",
      "HISTSIZE=1000\r\n",
      "SSH_CLIENT=203.246.112.118 54595 22\r\n",
      "PYDEVD_USE_FRAME_EVAL=NO\r\n",
      "SSH_TTY=/dev/pts/0\r\n",
      "USER=ec2-user\r\n",
      "LS_COLORS=rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.axv=38;5;13:*.anx=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:\r\n",
      "LD_LIBRARY_PATH=/opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:\r\n",
      "JPY_PARENT_PID=6354\r\n",
      "PAGER=cat\r\n",
      "VIRTUAL_ENV=/home/ec2-user/tensorflow_venv\r\n",
      "PATH=/home/ec2-user/tensorflow_venv/bin:/opt/amazon/openmpi/bin/:/opt/amazon/efa/bin/:/usr/local/cuda/bin:/usr/libexec/gcc/x86_64-redhat-linux/7:/opt/aws/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/ec2-user/.local/bin:/home/ec2-user/bin:/opt/aws/neuron/bin\r\n",
      "MAIL=/var/spool/mail/ec2-user\r\n",
      "_=/usr/bin/env\r\n",
      "PWD=/home/ec2-user/cloud-hw-inference/Inferentia/image_classification\r\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\r\n",
      "LANG=ko_KR.UTF-8\r\n",
      "MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles\r\n",
      "LOADEDMODULES=\r\n",
      "HISTCONTROL=ignoredups\r\n",
      "HOME=/home/ec2-user\r\n",
      "SHLVL=2\r\n",
      "LOGNAME=ec2-user\r\n",
      "SSH_CONNECTION=203.246.112.118 54595 172.31.61.116 22\r\n",
      "MODULESHOME=/usr/share/Modules\r\n",
      "LESSOPEN=||/usr/bin/lesspipe.sh %s\r\n",
      "TF2_BEHAVIOR=1\r\n",
      "XDG_RUNTIME_DIR=/run/user/1000\r\n",
      "GIT_PAGER=cat\r\n",
      "BASH_FUNC_module()=() {  eval `/usr/bin/modulecmd bash $*`\r\n",
      "}\r\n",
      "NEURON_CC_FLAGS=--neuroncore-pipeline-cores=1\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 02:02:28.347267: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-11-17 02:02:28.347442: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-11-17 02:02:28.348158: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2999995000 Hz\n",
      "2022-11-17 02:02:28.360377: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-11-17 02:02:28.360494: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-11-17 02:02:28.362846: I tensorflow/neuron/grappler/convert/segment.cc:456] There are 3 ops of 2 different types in the graph that are not compiled by neuron-cc: Placeholder, NoOp, (For more information see https://awsdocs-neuron.readthedocs-hosted.com/en/latest/release-notes/neuron-cc-ops/neuron-cc-ops-tensorflow.html).\n",
      "2022-11-17 02:02:28.364964: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-11-17 02:02:28.365037: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-11-17 02:02:28.417032: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/vgg16_conv64_inf1_saved_models/models/vgg16_conv64_batch_1_inf1_cores_1/assets\n",
      "Compile time: 7.50426983833313\n",
      "models/vgg16_conv64_inf1_saved_models/models/vgg16_conv64_batch_1_inf1_cores_1\n",
      "None\n",
      "----------- Done! ----------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inf1_model_dir = f'{model_name}_inf1_saved_models'\n",
    "saved_model_dir = f'{model_name}'\n",
    "\n",
    "\n",
    "# testing batch size\n",
    "batch_list = [1]\n",
    "num_of_cores = [1]\n",
    "for batch in batch_list:\n",
    "    for core in num_of_cores:\n",
    "        print('batch size:', batch,'core nums', core,'compile start')\n",
    "        compile_inf1_model(saved_model_dir, inf1_model_dir, batch_size=batch, num_cores=core)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Neuron TensorFlow)",
   "language": "python",
   "name": "tensorflow_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
