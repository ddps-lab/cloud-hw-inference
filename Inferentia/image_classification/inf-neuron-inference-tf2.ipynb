{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Inferentia inference on Amazon EC2 Inf1 instance\n",
    "This example demonstrates AWS Inferentia inference with TensorFlow and AWS Neuron SDK compiler and runtime\n",
    "\n",
    "This example was tested on Amazon EC2 `inf1.xlarge` the following AWS Deep Learning AMI: \n",
    "`Deep Learning AMI (Ubuntu 18.04) Version 35.0`\n",
    "\n",
    "Run this notebook using the following conda environment:\n",
    "`aws_neuron_tensorflow_p36`\n",
    "\n",
    "Prepare your imagenet validation TFRecord files using the following helper script:\n",
    "https://github.com/tensorflow/models/blob/archive/research/inception/inception/data/download_and_preprocess_imagenet.sh\n",
    "\n",
    "Save it to `/home/ubuntu/datasets/` or update the dataset location in the `get_dataset()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "# !/opt/aws/neuron/bin/neuron-cli reset\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.neuron as tfn\n",
    "import tensorflow.compat.v1.keras as keras\n",
    "from tensorflow.keras.applications import ( \n",
    "    xception,\n",
    "    vgg16,\n",
    "    vgg19,\n",
    "    resnet,\n",
    "    resnet50,\n",
    "    resnet_v2,\n",
    "    inception_v3,\n",
    "    inception_resnet_v2,\n",
    "    mobilenet,\n",
    "    densenet,\n",
    "    nasnet,\n",
    "    mobilenet_v2\n",
    ")\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from concurrent import futures\n",
    "from itertools import compress\n",
    "\n",
    "models = {\n",
    "    'xception':xception,\n",
    "    'vgg16':vgg16,\n",
    "    'vgg19':vgg19,\n",
    "    'resnet50':resnet50,\n",
    "    'resnet101':resnet,\n",
    "    'resnet152':resnet,\n",
    "    'resnet50_v2':resnet_v2,\n",
    "    'resnet101_v2':resnet_v2,\n",
    "    'resnet152_v2':resnet_v2,\n",
    "#     'resnext50':resnext,\n",
    "#     'resnext101':resnext,\n",
    "    'inception_v3':inception_v3,\n",
    "    'inception_resnet_v2':inception_resnet_v2,\n",
    "    'mobilenet':mobilenet,\n",
    "    'densenet121':densenet,\n",
    "    'densenet169':densenet,\n",
    "    'densenet201':densenet,\n",
    "    'nasnetlarge':nasnet,\n",
    "    'nasnetmobile':nasnet,\n",
    "    'mobilenet_v2':mobilenet_v2\n",
    "}\n",
    "\n",
    "models_detail = {\n",
    "#     'xception':xception.Xception(weights='imagenet',include_top=False),\n",
    "#     'vgg16':vgg16.VGG16(weights='imagenet'),\n",
    "#     'vgg19':vgg19.VGG19(weights='imagenet'),\n",
    "#     'resnet50':resnet.ResNet50(weights='imagenet'),\n",
    "#     'resnet101':resnet.ResNet101(weights='imagenet'),\n",
    "#     'resnet152':resnet.ResNet152(weights='imagenet'),\n",
    "#     'resnet50_v2':resnet_v2.ResNet50V2(weights='imagenet'),\n",
    "#     'resnet101_v2':resnet_v2.ResNet101V2(weights='imagenet'),\n",
    "#     'resnet152_v2':resnet_v2.ResNet152V2(weights='imagenet'),\n",
    "#     'resnext50':resnext.ResNeXt50(weights='imagenet'),\n",
    "#     'resnext101':resnext.ResNeXt101(weights='imagenet'),\n",
    "#     'inception_v3':inception_v3.InceptionV3(weights='imagenet',include_top=False),\n",
    "#     'inception_resnet_v2':inception_resnet_v2.InceptionResNetV2(weights='imagenet'),\n",
    "#     'mobilenet':mobilenet.MobileNet(weights='imagenet'),\n",
    "#     'densenet121':densenet.DenseNet121(weights='imagenet'),\n",
    "#     'densenet169':densenet.DenseNet169(weights='imagenet'),\n",
    "#     'densenet201':densenet.DenseNet201(weights='imagenet'),\n",
    "#     'nasnetlarge':nasnet.NASNetLarge(weights='imagenet'),\n",
    "#     'nasnetmobile':nasnet.NASNetMobile(weights='imagenet'),\n",
    "#     'mobilenet_v2':mobilenet_v2.MobileNetV2(weights='imagenet')\n",
    "}\n",
    "\n",
    "print('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50 FP32 saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export SavedModel\n",
    "# model_type = 'resnet50'\n",
    "\n",
    "# saved_model_dir = f'{model_type}_saved_model'\n",
    "# shutil.rmtree(saved_model_dir, ignore_errors=True)\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "# model = ResNet50(weights='imagenet')\n",
    "# tf.saved_model.simple_save(session = keras.backend.get_session(),\n",
    "#                            export_dir = saved_model_dir,\n",
    "#                            inputs = {'input_1:0': model.inputs[0]},\n",
    "#                            outputs = {'probs/Softmax:0': model.outputs[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile models with different batch sizes and cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_inf1_model(saved_model_dir, inf1_model_dir, batch_size=1, num_cores=1, use_static_weights=False):\n",
    "    print(f'-----------batch size: {batch_size}, num cores: {num_cores}----------')\n",
    "    print('Compiling...')\n",
    "    \n",
    "    compiled_model_dir = f'{model_type}_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "    inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "    shutil.rmtree(inf1_compiled_model_dir, ignore_errors=True)\n",
    "\n",
    "    example_input = np.zeros([batch_size,224,224,3], dtype='float32')\n",
    "\n",
    "    compiler_args = ['--verbose','1', '--neuroncore-pipeline-cores', str(num_cores)]\n",
    "    if use_static_weights:\n",
    "        compiler_args.append('--static-weights')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    compiled_res = tfn.saved_model.compile(model_dir = saved_model_dir,\n",
    "                            model_feed_dict={'input_1:0': example_input},\n",
    "                            new_model_dir = inf1_compiled_model_dir,\n",
    "                            dynamic_batch_size=True,\n",
    "                            compiler_args = compiler_args)\n",
    "    print(f'Compile time: {time.time() - start_time}')\n",
    "    \n",
    "    compile_success = False\n",
    "    perc_on_inf = compiled_res['OnNeuronRatio'] * 100\n",
    "    if perc_on_inf > 50:\n",
    "        compile_success = True\n",
    "            \n",
    "    print(inf1_compiled_model_dir)\n",
    "    print(compiled_res)\n",
    "    print('----------- Done! ----------- \\n')\n",
    "    \n",
    "    return compile_success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `tf.data` to read ImageNet validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_image_record(record):\n",
    "    feature_map = {'image/encoded': tf.io.FixedLenFeature([], tf.string, ''),\n",
    "                  'image/class/label': tf.io.FixedLenFeature([1], tf.int64, -1)}\n",
    "    obj = tf.io.parse_single_example(serialized=record, features=feature_map)\n",
    "    imgdata = obj['image/encoded']\n",
    "    label = tf.cast(obj['image/class/label'], tf.int32)   \n",
    "    return imgdata, label\n",
    "\n",
    "def val_preprocessing(record):\n",
    "    imgdata, label = deserialize_image_record(record)\n",
    "    label -= 1\n",
    "    image = tf.io.decode_jpeg(imgdata, channels=3, \n",
    "                              fancy_upscaling=False, \n",
    "                              dct_method='INTEGER_FAST')\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "    height = tf.cast(shape[0], tf.float32)\n",
    "    width = tf.cast(shape[1], tf.float32)\n",
    "    side = tf.cast(tf.convert_to_tensor(256, dtype=tf.int32), tf.float32)\n",
    "\n",
    "    scale = tf.cond(tf.greater(height, width),\n",
    "                  lambda: side / width,\n",
    "                  lambda: side / height)\n",
    "    \n",
    "    new_height = tf.cast(tf.math.rint(height * scale), tf.int32)\n",
    "    new_width = tf.cast(tf.math.rint(width * scale), tf.int32)\n",
    "    \n",
    "    image = tf.image.resize(image, [new_height, new_width], method='bicubic')\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 224, 224)\n",
    "    \n",
    "    image = models[model_type].preprocess_input(image)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def get_dataset(batch_size, use_cache=False):\n",
    "    data_dir = '/home/ubuntu/datasets/images-50000/*'\n",
    "    files = tf.io.gfile.glob(os.path.join(data_dir))\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    \n",
    "    dataset = dataset.map(map_func=val_preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat(count=1)\n",
    "    \n",
    "    if use_cache:\n",
    "        shutil.rmtree('tfdatacache', ignore_errors=True)\n",
    "        os.mkdir('tfdatacache')\n",
    "        dataset = dataset.cache(f'./tfdatacache/imagenet_val')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single AWS Inferentia chip execution\n",
    "* Single core compiled models with automatic data parallel model upto 4 cores\n",
    "* Multi-core compiled models for pipeline execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "    \n",
    "def inf1_predict_benchmark_single_threaded(neuron_saved_model_name, batch_size, user_batch_size, num_cores, use_cache=False, warm_up=10):\n",
    "    print(f'Running model {neuron_saved_model_name}, user_batch_size: {user_batch_size}\\n')\n",
    "\n",
    "    model_inf1 = tf.saved_model.load(neuron_saved_model_name)\n",
    "    \n",
    "    inference_function = model_inf1.signatures['serving_default']\n",
    "    walltime_start = time.time()\n",
    "    first_iter_time = 0\n",
    "    iter_times = []\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    total_datas = 50000\n",
    "    display_every = 1000\n",
    "    display_threshold = display_every\n",
    "    \n",
    "    ds = get_dataset(user_batch_size, use_cache)\n",
    "    load_start = time.time()\n",
    "    load_time = time.time() - load_start\n",
    "    counter = 0\n",
    "    print(model_inf1)\n",
    "    for batch, batch_labels in ds:\n",
    "        start_time = time.time()\n",
    "        yhat_np = inference_function(batch)\n",
    "        if counter ==0:\n",
    "            first_iter_time = time.time() - start_time\n",
    "        else:\n",
    "            iter_times.append(time.time() - start_time)\n",
    "        actual_labels.extend(label for label_list in batch_labels for label in label_list)\n",
    "        pred_labels.extend(list(np.argmax(yhat_np, axis=1)))\n",
    "\n",
    "        if counter*batch_size >= display_threshold:\n",
    "            print(f'Images {counter*batch_size}/{total_datas}. Average i/s {np.mean(batch_size/np.array(iter_times[-display_every:]))}')\n",
    "            display_threshold+=display_every\n",
    "\n",
    "        counter+=1\n",
    "    iter_times = np.array(iter_times)\n",
    "    acc_inf1 = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "    results = pd.DataFrame(columns = [f'inf1_tf2_{model_type}_{batch_size}'])\n",
    "    results.loc['batch_size']              = [batch_size]\n",
    "    results.loc['accuracy']                = [acc_inf1]\n",
    "    results.loc['first_prediction_time']   = [first_iter_time]\n",
    "    results.loc['average_prediction_time'] = [np.mean(iter_times)]\n",
    "    results.loc['load_time']               = [load_time]\n",
    "    results.loc['wall_time']               = [time.time() - walltime_start]\n",
    "\n",
    "    return results, iter_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: vgg16_inf1_saved_models/vgg16_batch_64_inf1_cores_1\n",
      "Running model vgg16_inf1_saved_models/vgg16_batch_64_inf1_cores_1, user_batch_size: 4096\n",
      "\n",
      "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject object at 0x7f2144734e48>\n"
     ]
    },
    {
     "ename": "UnavailableError",
     "evalue": "2 root error(s) found.\n  (0) Unavailable:  grpc server unix:/run/neuron.sock is unavailable. Please check the status of neuron-rtd service by `systemctl is-active neuron-rtd`. If it shows `inactive`, please install the service by `sudo apt-get install aws-neuron-runtime`. If `aws-neuron-runtime` is already installed, you may activate neuron-rtd service by `sudo systemctl restart neuron-rtd`.\n\t [[{{node StatefulPartitionedCall/aws_neuron_model/StatefulPartitionedCall/neuron_op_dd78f53bee0a8715}}]]\n  (1) Unavailable:  grpc server unix:/run/neuron.sock is unavailable. Please check the status of neuron-rtd service by `systemctl is-active neuron-rtd`. If it shows `inactive`, please install the service by `sudo apt-get install aws-neuron-runtime`. If `aws-neuron-runtime` is already installed, you may activate neuron-rtd service by `sudo systemctl restart neuron-rtd`.\n\t [[{{node StatefulPartitionedCall/aws_neuron_model/StatefulPartitionedCall/neuron_op_dd78f53bee0a8715}}]]\n\t [[StatefulPartitionedCall/aws_neuron_model/StatefulPartitionedCall/neuron_op_dd78f53bee0a8715/_4]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_signature_wrapper_44]\n\nFunction call stack:\nsignature_wrapper -> signature_wrapper\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1720\u001b[0m           return self._call_with_structured_signature(args, kwargs,\n\u001b[0;32m-> 1721\u001b[0;31m                                                       cancellation_manager)\n\u001b[0m\u001b[1;32m   1722\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstructured_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_with_structured_signature\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1797\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_function_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structured_signature_check_missing_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structured_signature_check_unexpected_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_structured_signature_check_missing_args\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1818\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structured_signature_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m           \", \".join(sorted(missing_arguments))))\n\u001b[0m\u001b[1;32m   1820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: signature_wrapper(*, input_1) missing required arguments: input_1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnavailableError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9e3078f9ebbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                                                              \u001b[0mnum_cores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_cores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                                                              \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                                                                              warm_up=10)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0miter_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-c455c2b8f815>\u001b[0m in \u001b[0;36minf1_predict_benchmark_single_threaded\u001b[0;34m(neuron_saved_model_name, batch_size, user_batch_size, num_cores, use_cache, warm_up)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0myhat_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mfirst_iter_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1709\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mdo\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m     \"\"\"\n\u001b[0;32m-> 1711\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1723\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1724\u001b[0m             return self._call_with_flat_signature(args, kwargs,\n\u001b[0;32m-> 1725\u001b[0;31m                                                   cancellation_manager)\n\u001b[0m\u001b[1;32m   1726\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mstructured_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_with_flat_signature\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                         \"got {} ({})\".format(self._flat_signature_summary(), i,\n\u001b[1;32m   1777\u001b[0m                                              type(arg).__name__, str(arg)))\n\u001b[0;32m-> 1778\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_with_structured_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m    116\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_unused_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     return super(_WrapperFunction, self)._call_flat(args, captured_inputs,\n\u001b[0;32m--> 118\u001b[0;31m                                                     cancellation_manager)\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnavailableError\u001b[0m: 2 root error(s) found.\n  (0) Unavailable:  grpc server unix:/run/neuron.sock is unavailable. Please check the status of neuron-rtd service by `systemctl is-active neuron-rtd`. If it shows `inactive`, please install the service by `sudo apt-get install aws-neuron-runtime`. If `aws-neuron-runtime` is already installed, you may activate neuron-rtd service by `sudo systemctl restart neuron-rtd`.\n\t [[{{node StatefulPartitionedCall/aws_neuron_model/StatefulPartitionedCall/neuron_op_dd78f53bee0a8715}}]]\n  (1) Unavailable:  grpc server unix:/run/neuron.sock is unavailable. Please check the status of neuron-rtd service by `systemctl is-active neuron-rtd`. If it shows `inactive`, please install the service by `sudo apt-get install aws-neuron-runtime`. If `aws-neuron-runtime` is already installed, you may activate neuron-rtd service by `sudo systemctl restart neuron-rtd`.\n\t [[{{node StatefulPartitionedCall/aws_neuron_model/StatefulPartitionedCall/neuron_op_dd78f53bee0a8715}}]]\n\t [[StatefulPartitionedCall/aws_neuron_model/StatefulPartitionedCall/neuron_op_dd78f53bee0a8715/_4]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_signature_wrapper_44]\n\nFunction call stack:\nsignature_wrapper -> signature_wrapper\n"
     ]
    }
   ],
   "source": [
    "model_type = 'vgg16'\n",
    "# https://github.com/tensorflow/tensorflow/issues/29931\n",
    "temp = tf.zeros([8, 224, 224, 3])\n",
    "_ = models[model_type].preprocess_input(temp)\n",
    "\n",
    "# testing batch size\n",
    "batch_list = [64]\n",
    "num_of_cores = [1]\n",
    "user_batchs = [64]\n",
    "inf1_model_dir = f'{model_type}_inf1_saved_models'\n",
    "\n",
    "for user_batch in user_batchs:\n",
    "    iter_ds = pd.DataFrame()\n",
    "    results = pd.DataFrame()\n",
    "    for batch_size in batch_list:\n",
    "        for num_cores in num_of_cores:\n",
    "            opt ={'batch_size': batch_size, 'num_cores': num_of_cores}\n",
    "            compiled_model_dir = f'{model_type}_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "            inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "\n",
    "            print(f'inf1_compiled_model_dir: {inf1_compiled_model_dir}')\n",
    "            col_name = lambda opt: f'inf1_{batch_size}_multicores_{num_cores}'\n",
    "\n",
    "            res, iter_times = inf1_predict_benchmark_single_threaded(inf1_compiled_model_dir,\n",
    "                                                                             batch_size = batch_size,\n",
    "                                                                             user_batch_size = batch_size*user_batch,\n",
    "                                                                             num_cores = num_cores,\n",
    "                                                                             use_cache=False, \n",
    "                                                                             warm_up=10)\n",
    "\n",
    "        iter_ds = pd.concat([iter_ds, pd.DataFrame(iter_times, columns=[col_name(opt)])], axis=1)\n",
    "        results = pd.concat([results, res], axis=1)\n",
    "    display(results)\n",
    "    results.to_csv(f'{model_type}_batch_size_{batch_size}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuron_tensorflow_p36",
   "language": "python",
   "name": "aws_neuron_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
