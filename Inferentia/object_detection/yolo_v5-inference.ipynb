{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate YOLO v3 on Inferentia\n",
    "## Note: this tutorial runs on tensorflow-neuron 1.x only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This tutorial walks through compiling and evaluating YOLO v3 model on Inferentia using the AWS Neuron SDK.\n",
    "\n",
    "\n",
    "In this tutorial we provide two main sections:\n",
    "\n",
    "1. Download Dataset and Generate Pretrained SavedModel\n",
    "\n",
    "2. Compile the YOLO v3 model.\n",
    "\n",
    "3. Deploy the same compiled model.\n",
    "\n",
    "Before running the following verify this Jupyter notebook is running “conda_aws_neuron_tensorflow_p36” kernel. You can select the Kernel from the “Kernel -> Change Kernel” option on the top of this Jupyter notebook page.\n",
    "\n",
    "Instructions of how to setup Neuron Tensorflow environment and run the tutorial as a Jupyter notebook are available in the Tutorial main page [Tensorflow-YOLO_v3 Tutorial](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/neuron-frameworks/tensorflow-neuron/tutorials/yolo_v3_demo/yolo_v3_demo.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo requires the following pip packages:\n",
    "\n",
    "`pillow matplotlib pycocotools`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model on Inferentia\n",
    "## Part 3:Evaluate Model Quality after Compilation\n",
    "\n",
    "### Define evaluation functions\n",
    "We first define some handy helper functions for running evaluation on the COCO 2017 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-01 07:11:48.584117: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-07-01 07:11:49.576165: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-01 07:11:49.679340: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-07-01 07:11:49.679372: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-49-69.us-west-2.compute.internal): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def cocoapi_eval(jsonfile,\n",
    "                 style,\n",
    "                 coco_gt=None,\n",
    "                 anno_file=None,\n",
    "                 max_dets=(100, 300, 1000)):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        jsonfile: Evaluation json file, eg: bbox.json, mask.json.\n",
    "        style: COCOeval style, can be `bbox` , `segm` and `proposal`.\n",
    "        coco_gt: Whether to load COCOAPI through anno_file,\n",
    "                 eg: coco_gt = COCO(anno_file)\n",
    "        anno_file: COCO annotations file.\n",
    "        max_dets: COCO evaluation maxDets.\n",
    "    \"\"\"\n",
    "    assert coco_gt is not None or anno_file is not None\n",
    "\n",
    "    if coco_gt is None:\n",
    "        coco_gt = COCO(anno_file)\n",
    "    print(\"Start evaluate...\")\n",
    "    coco_dt = coco_gt.loadRes(jsonfile)\n",
    "    if style == 'proposal':\n",
    "        coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "        coco_eval.params.useCats = 0\n",
    "        coco_eval.params.maxDets = list(max_dets)\n",
    "    else:\n",
    "        coco_eval = COCOeval(coco_gt, coco_dt, style)\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "    return coco_eval.stats\n",
    "\n",
    "\n",
    "def bbox_eval(anno_file, bbox_list):\n",
    "    coco_gt = COCO(anno_file)\n",
    "\n",
    "    outfile = 'bbox_detections.json'\n",
    "    print('Generating json file...')\n",
    "    with open(outfile, 'w') as f:\n",
    "        json.dump(bbox_list, f)\n",
    "\n",
    "    map_stats = cocoapi_eval(outfile, 'bbox', coco_gt=coco_gt)\n",
    "    return map_stats\n",
    "\n",
    "\n",
    "def get_image_as_bytes(images, eval_pre_path, user_batch_size):\n",
    "    batch_im_id_list = []\n",
    "    batch_im_name_list = []\n",
    "    batch_img_bytes_list = []\n",
    "    n = len(images)\n",
    "    batch_im_id = []\n",
    "    batch_im_name = []\n",
    "    batch_img_bytes = []\n",
    "    for i, im in enumerate(images):\n",
    "        im_id = im['id']\n",
    "        file_name = im['file_name']\n",
    "        if i % user_batch_size == 0 and i != 0:\n",
    "            batch_im_id_list.append(batch_im_id)\n",
    "            batch_im_name_list.append(batch_im_name)\n",
    "            batch_img_bytes_list.append(batch_img_bytes)\n",
    "            batch_im_id = []\n",
    "            batch_im_name = []\n",
    "            batch_img_bytes = []\n",
    "        batch_im_id.append(im_id)\n",
    "        batch_im_name.append(file_name)\n",
    "\n",
    "        with open(os.path.join(eval_pre_path, file_name), 'rb') as f:\n",
    "            batch_img_bytes.append(f.read())\n",
    "    return batch_im_id_list, batch_im_name_list, batch_img_bytes_list\n",
    "\n",
    "\n",
    "def analyze_bbox(results, batch_im_id, _clsid2catid):\n",
    "    bbox_list = []\n",
    "    k = 0\n",
    "    for boxes, scores, classes in zip(results['boxes'], results['scores'], results['classes']):\n",
    "        if boxes is not None:\n",
    "            im_id = batch_im_id[k]\n",
    "            n = len(boxes)\n",
    "            for p in range(n):\n",
    "                clsid = classes[p]\n",
    "                score = scores[p]\n",
    "                xmin, ymin, xmax, ymax = boxes[p]\n",
    "                catid = (_clsid2catid[int(clsid)])\n",
    "                w = xmax - xmin + 1\n",
    "                h = ymax - ymin + 1\n",
    "\n",
    "                bbox = [xmin, ymin, w, h]\n",
    "                # Round to the nearest 10th to avoid huge file sizes, as COCO suggests\n",
    "                bbox = [round(float(x) * 10) / 10 for x in bbox]\n",
    "                bbox_res = {\n",
    "                    'image_id': im_id,\n",
    "                    'category_id': catid,\n",
    "                    'bbox': bbox,\n",
    "                    'score': float(score),\n",
    "                }\n",
    "                bbox_list.append(bbox_res)\n",
    "        k += 1\n",
    "    return bbox_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the actual evaluation loop. To fully utilize all four cores on one Inferentia, the optimal setup is to run multi-threaded inference using a `ThreadPoolExecutor`. The following cell is a multi-threaded adaptation of the evaluation routine at https://github.com/miemie2013/Keras-YOLOv4/blob/910c4c6f7265f5828fceed0f784496a0b46516bf/tools/cocotools.py#L97."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "\n",
    "def evaluate(yolo_predictor, images, eval_pre_path, anno_file, eval_batch_size, _clsid2catid, user_batch_size, num_cores):\n",
    "    batch_im_id_list, batch_im_name_list, batch_img_bytes_list = get_image_as_bytes(images, eval_pre_path, user_batch_size)\n",
    "    walltime_start = time.time()\n",
    "    # warm up\n",
    "#     yolo_predictor({'image': np.array(batch_img_bytes_list[0], dtype=object)})\n",
    "\n",
    "#     with futures.ThreadPoolExecutor(4) as exe:\n",
    "#         fut_im_list = []\n",
    "#         fut_list = []\n",
    "#         start_time = time.time()\n",
    "#         for batch_im_id, batch_im_name, batch_img_bytes in zip(batch_im_id_list, batch_im_name_list, batch_img_bytes_list):\n",
    "#             if len(batch_img_bytes) != eval_batch_size:\n",
    "#                 continue\n",
    "#             fut = exe.submit(yolo_predictor, {'image': np.array(batch_img_bytes, dtype=object)})\n",
    "#             fut_im_list.append((batch_im_id, batch_im_name))\n",
    "#             fut_list.append(fut)\n",
    "#         bbox_list = []\n",
    "#         count = 0\n",
    "#         for (batch_im_id, batch_im_name), fut in zip(fut_im_list, fut_list):\n",
    "#             results = fut.result()\n",
    "#             bbox_list.extend(analyze_bbox(results, batch_im_id, _clsid2catid))\n",
    "#             for _ in batch_im_id:\n",
    "#                 count += 1\n",
    "#                 if count % 100 == 0:\n",
    "#                     print('Test iter {}'.format(count))\n",
    "#         print('==================== Performance Measurement ====================')\n",
    "#         print('Finished inference on {} images in {} seconds'.format(len(images), time.time() - start_time))\n",
    "#         print('=================================================================')\n",
    "#     # start evaluation\n",
    "#     box_ap_stats = bbox_eval(anno_file, bbox_list)\n",
    "    iter_times = []\n",
    "    counter = 0\n",
    "    first_iter_time = 0\n",
    "    fut_im_list = []\n",
    "    fut_list = []\n",
    "    for batch_im_id, batch_im_name, batch_img_bytes in zip(batch_im_id_list, batch_im_name_list, batch_img_bytes_list):\n",
    "        if len(batch_img_bytes) != user_batch_size:\n",
    "            continue\n",
    "        iter_start = time.time()\n",
    "        fut = yolo_predictor({'image': np.array(batch_img_bytes, dtype=object)})\n",
    "        fut_im_list.append((batch_im_id, batch_im_name))\n",
    "        fut_list.append(fut)\n",
    "        if counter == 0:\n",
    "            first_iter_time = time.time() - iter_start\n",
    "        else:\n",
    "            iter_times.append(time.time() - iter_start)\n",
    "        counter +=1\n",
    "    bbox_list = []\n",
    "    counter = 0\n",
    "    for (batch_im_id, batch_im_name), fut in zip(fut_im_list, fut_list):\n",
    "        results = fut\n",
    "        bbox_list.extend(analyze_bbox(results, batch_im_id, _clsid2catid))\n",
    "        for _ in batch_im_id:\n",
    "            counter += 1\n",
    "            if counter % 100 == 0:\n",
    "                print('Test iter {}'.format(counter))\n",
    "    \n",
    "    print('==================== Performance Measurement ====================')\n",
    "    print('Finished inference on {} images in {} seconds'.format(len(images), time.time() - walltime_start))\n",
    "    print('=================================================================')\n",
    "    \n",
    "    results = pd.DataFrame(columns = [f'inf1_compiled_batch_size_{eval_batch_size}_compiled_cores_{num_cores}'])\n",
    "    results.loc['compiled_batch_size'] = [eval_batch_size]\n",
    "    results.loc['user_batch_size'] = [user_batch_size]\n",
    "    results.loc['first_prediction_time'] = [first_iter_time]\n",
    "    results.loc['average_prediction_time'] = [np.mean(iter_times)]\n",
    "    results.loc['wall_time'] = [time.time() - walltime_start]\n",
    "    box_ap_stats = bbox_eval(anno_file, bbox_list)\n",
    "    return box_ap_stats, results, iter_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate mean average precision (mAP) score\n",
    "Here is the code to calculate mAP scores of the YOLO v3 model. The expected mAP score is around 0.328 if we use the pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: yolo_v5_coco_inf1_saved_models\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/cloud-hw-inference/Inferentia/tensorflow_venv2.5.3/lib64/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  if __name__ == \"__main__\":\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         inf1_tf2_yolo_v5_coco_1\n",
      "average_prediction_time                 0.454616\n",
      "load_time                               0.101168\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "def filenames_to_input(file_list):\n",
    "    imgs = []\n",
    "    for file in file_list:\n",
    "        img = Image.open(file)\n",
    "        img.convert('RGB')\n",
    "        img = img.resize((640, 640), Image.ANTIALIAS)\n",
    "        img = np.array(img, dtype='float32')\n",
    "        # if image is grayscale, convert to 3 channels\n",
    "        if len(img.shape) != 3:\n",
    "            img = np.repeat(img[..., np.newaxis], 3, -1)\n",
    "        # batchsize, 224, 224, 3\n",
    "        img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "        imgs.append(img)\n",
    "\n",
    "    batch_imgs = np.vstack(imgs)\n",
    "    return batch_imgs\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "val_coco_root = './val2017'\n",
    "val_annotate = './annotations/instances_val2017.json'\n",
    "clsid2catid = {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 13, 12: 14, 13: 15, 14: 16,\n",
    "               15: 17, 16: 18, 17: 19, 18: 20, 19: 21, 20: 22, 21: 23, 22: 24, 23: 25, 24: 27, 25: 28, 26: 31,\n",
    "               27: 32, 28: 33, 29: 34, 30: 35, 31: 36, 32: 37, 33: 38, 34: 39, 35: 40, 36: 41, 37: 42, 38: 43,\n",
    "               39: 44, 40: 46, 41: 47, 42: 48, 43: 49, 44: 50, 45: 51, 46: 52, 47: 53, 48: 54, 49: 55, 50: 56,\n",
    "               51: 57, 52: 58, 53: 59, 54: 60, 55: 61, 56: 62, 57: 63, 58: 64, 59: 65, 60: 67, 61: 70, 62: 72,\n",
    "               63: 73, 64: 74, 65: 75, 66: 76, 67: 77, 68: 78, 69: 79, 70: 80, 71: 81, 72: 82, 73: 84, 74: 85,\n",
    "               75: 86, 76: 87, 77: 88, 78: 89, 79: 90}\n",
    "\n",
    "model_type = 'yolo_v5_coco'\n",
    "\n",
    "batch_list = [1]\n",
    "num_of_cores = [1]\n",
    "user_batchs = [1]\n",
    "inf1_model_dir = f'{model_type}_inf1_saved_models'\n",
    "for user_batch in user_batchs:\n",
    "    iter_ds = pd.DataFrame()\n",
    "    results = pd.DataFrame()\n",
    "    for eval_batch_size in batch_list:\n",
    "        for num_cores in num_of_cores:\n",
    "            opt ={'batch_size': eval_batch_size, 'num_cores': num_of_cores}\n",
    "#             compiled_model_dir = f'{model_type}_batch_{eval_batch_size}_inf1_cores_{num_cores}'\n",
    "#             inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "            inf1_compiled_model_dir = inf1_model_dir\n",
    "            print(f'inf1_compiled_model_dir: {inf1_compiled_model_dir}')\n",
    "            col_name = lambda opt: f'inf1_{eval_batch_size}_multicores_{num_cores}'\n",
    "\n",
    "            with open(val_annotate, 'r', encoding='utf-8') as f2:\n",
    "                for line in f2:\n",
    "                    line = line.strip()\n",
    "                    dataset = json.loads(line)\n",
    "                    images = dataset['images']\n",
    "            start_time = time.time()\n",
    "            yolo_pred = load_model(inf1_compiled_model_dir)\n",
    "            load_time = time.time() - start_time\n",
    "            iter_times = []\n",
    "            \n",
    "            image_list = glob.glob(val_coco_root + '/*')\n",
    "            for image in image_list:\n",
    "                image = filenames_to_input([image])\n",
    "                start_time = time.time()\n",
    "                res = yolo_pred(image)\n",
    "                iter_times.append(time.time() - start_time)\n",
    "                break\n",
    "            \n",
    "            iter_times = np.array(iter_times)\n",
    "            \n",
    "            results = pd.DataFrame(columns = [f'inf1_tf2_{model_type}_{1}'])\n",
    "#             results.loc['batch_size']              = [batch_size]\n",
    "#             results.loc['first_prediction_time']   = [first_iter_time]\n",
    "            results.loc['average_prediction_time'] = [np.mean(iter_times)]\n",
    "            results.loc['load_time']               = [load_time]\n",
    "#             box_ap, res, iter_times = evaluate(yolo_pred,\n",
    "#                                                images,\n",
    "#                                                val_coco_root,\n",
    "#                                                val_annotate,\n",
    "#                                                eval_batch_size,\n",
    "#                                                clsid2catid,\n",
    "#                                                eval_batch_size * user_batch, \n",
    "#                                                num_cores)\n",
    "\n",
    "#         iter_ds = pd.concat([iter_ds, pd.DataFrame(iter_times, columns=[col_name(opt)])], axis=1)\n",
    "#         results = pd.concat([results, res], axis=1)\n",
    "#     display(results)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_venv2.5.3",
   "language": "python",
   "name": "tensorflow_venv2.5.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
