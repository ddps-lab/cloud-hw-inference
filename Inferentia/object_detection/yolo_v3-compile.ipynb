{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate YOLO v3 on Inferentia\n",
    "## Note: this tutorial runs on tensorflow-neuron 1.x only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This tutorial walks through compiling and evaluating YOLO v3 model on Inferentia using the AWS Neuron SDK.\n",
    "\n",
    "\n",
    "In this tutorial we provide two main sections:\n",
    "\n",
    "1. Download Dataset and Generate Pretrained SavedModel\n",
    "\n",
    "2. Compile the YOLO v3 model.\n",
    "\n",
    "3. Deploy the same compiled model.\n",
    "\n",
    "Before running the following verify this Jupyter notebook is running “conda_aws_neuron_tensorflow_p36” kernel. You can select the Kernel from the “Kernel -> Change Kernel” option on the top of this Jupyter notebook page.\n",
    "\n",
    "Instructions of how to setup Neuron Tensorflow environment and run the tutorial as a Jupyter notebook are available in the Tutorial main page [Tensorflow-YOLO_v3 Tutorial](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/neuron-frameworks/tensorflow-neuron/tutorials/yolo_v3_demo/yolo_v3_demo.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo requires the following pip packages:\n",
    "\n",
    "`pillow matplotlib pycocotools`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/ubuntu/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting pillow\n",
      "  Downloading Pillow-8.3.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.5 MB 144.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycocotools==2.0.2\n",
      "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\n",
      "Collecting setuptools>=18.0\n",
      "  Downloading setuptools-58.1.0-py3-none-any.whl (816 kB)\n",
      "\u001b[K     |████████████████████████████████| 816 kB 113.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cython>=0.27.3\n",
      "  Downloading Cython-0.29.24-cp36-cp36m-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 137.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil>=2.1\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "\u001b[K     |████████████████████████████████| 247 kB 133.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 140.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 106.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting numpy>=1.15\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.8 MB 132.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp36-cp36m-linux_x86_64.whl size=273279 sha256=d8c3fcfe0a662f3343253bfdbb963abd4911801fb8b00a531f161660eb69691f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-gkluu9mo/wheels/d8/c2/ba/8f5306f921c2e79ad7b09effdfed6bd966cfcf8c6fe55422d6\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: six, python-dateutil, pyparsing, pillow, numpy, kiwisolver, cycler, setuptools, matplotlib, cython, pycocotools\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 8.3.2\n",
      "    Uninstalling Pillow-8.3.2:\n",
      "      Successfully uninstalled Pillow-8.3.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: kiwisolver\n",
      "    Found existing installation: kiwisolver 1.3.1\n",
      "    Uninstalling kiwisolver-1.3.1:\n",
      "      Successfully uninstalled kiwisolver-1.3.1\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.10.0\n",
      "    Uninstalling cycler-0.10.0:\n",
      "      Successfully uninstalled cycler-0.10.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 58.0.4\n",
      "    Uninstalling setuptools-58.0.4:\n",
      "      Successfully uninstalled setuptools-58.0.4\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.3.4\n",
      "    Uninstalling matplotlib-3.3.4:\n",
      "      Successfully uninstalled matplotlib-3.3.4\n",
      "  Attempting uninstall: cython\n",
      "    Found existing installation: Cython 0.29.24\n",
      "    Uninstalling Cython-0.29.24:\n",
      "      Successfully uninstalled Cython-0.29.24\n",
      "  Attempting uninstall: pycocotools\n",
      "    Found existing installation: pycocotools 2.0.2\n",
      "    Uninstalling pycocotools-2.0.2:\n",
      "      Successfully uninstalled pycocotools-2.0.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 1.15.5 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n",
      "Successfully installed cycler-0.10.0 cython-0.29.24 kiwisolver-1.3.1 matplotlib-3.3.4 numpy-1.19.5 pillow-8.3.2 pycocotools-2.0.2 pyparsing-2.4.7 python-dateutil-2.8.2 setuptools-58.1.0 six-1.16.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install pillow matplotlib pycocotools==2.0.2 --force --extra-index-url=https://pip.repos.neuron.amazonaws.com\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1:  Download Dataset and Generate Pretrained SavedModel\n",
    "### Download COCO 2017 validation dataset\n",
    "\n",
    "We start by downloading the COCO validation dataset, which we will use to validate our model. The COCO 2017 dataset is widely used for object-detection, segmentation and image captioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  777M  100  777M    0     0  22.1M      0  0:00:35  0:00:35 --:--:-- 22.7M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  241M  100  241M    0     0  21.7M      0  0:00:11  0:00:11 --:--:-- 22.8M\n",
      "replace val2017/000000212226.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!curl -LO http://images.cocodataset.org/zips/val2017.zip\n",
    "!curl -LO http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!unzip -q val2017.zip\n",
    "!unzip annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Generate YOLO v3 tensorflow SavedModel (pretrained on COCO 2017 dataset)\n",
    "\n",
    "Script yolo_v3_coco_saved_model.py will generate a tensorflow SavedModel using pretrained weights from https://github.com/YunYang1994/tensorflow-yolov3/releases/download/v1.0/yolov3_coco.tar.gz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run yolo_v3_coco_saved_model.py ./yolo_v3_coco_saved_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tensorflow SavedModel can be loaded as a tensorflow predictor. When a JPEG format image is provided as input, the output result of the tensorflow predictor contains information for drawing bounding boxes and classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# launch predictor and run inference on an arbitrary image in the validation dataset\n",
    "yolo_pred_cpu = tf.contrib.predictor.from_saved_model('./yolo_v3_coco_saved_model')\n",
    "image_path = './val2017/000000581781.jpg'\n",
    "with open(image_path, 'rb') as f:\n",
    "    feeds = {'image': [f.read()]}\n",
    "results = yolo_pred_cpu(feeds)\n",
    "\n",
    "# load annotations to decode classification result\n",
    "with open('./annotations/instances_val2017.json') as f:\n",
    "    annotate_json = json.load(f)\n",
    "label_info = {idx+1: cat['name'] for idx, cat in enumerate(annotate_json['categories'])}\n",
    "\n",
    "# draw picture and bounding boxes\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(Image.open(image_path).convert('RGB'))\n",
    "wanted = results['scores'][0] > 0.1\n",
    "for xyxy, label_no_bg in zip(results['boxes'][0][wanted], results['classes'][0][wanted]):\n",
    "    xywh = xyxy[0], xyxy[1], xyxy[2] - xyxy[0], xyxy[3] - xyxy[1]\n",
    "    rect = patches.Rectangle((xywh[0], xywh[1]), xywh[2], xywh[3], linewidth=1, edgecolor='g', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    rx, ry = rect.get_xy()\n",
    "    rx = rx + rect.get_width() / 2.0\n",
    "    ax.annotate(label_info[label_no_bg + 1], (rx, ry), color='w', backgroundcolor='g', fontsize=10,\n",
    "                ha='center', va='center', bbox=dict(boxstyle='square,pad=0.01', fc='g', ec='none', alpha=0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:  Compile the Pretrained SavedModel for Neuron\n",
    "\n",
    "We make use of the Python compilation API `tfn.saved_model.compile` that is available in `tensorflow-neuron<2`. For the purpose of reducing Neuron runtime overhead, it is necessary to make use of arguments `no_fuse_ops` and `minimum_segment_size`.\n",
    "Compiled model is saved in ./yolo_v3_coco_saved_model_neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./yolo_v3_coco_saved_model/variables/variables\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import tensorflow as tf\n",
    "import tensorflow.neuron as tfn\n",
    "import os\n",
    "\n",
    "model_type = 'yolo_v3_coco'\n",
    "\n",
    "def no_fuse_condition(op):\n",
    "    return op.name.startswith('Preprocessor') or op.name.startswith('Postprocessor')\n",
    "\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, ['serve'], './yolo_v3_coco_saved_model')\n",
    "    no_fuse_ops = [op.name for op in sess.graph.get_operations() if no_fuse_condition(op)]\n",
    "def compile_inf1_model(saved_model_dir, inf1_model_dir, batch_size=1, num_cores=1, use_static_weights=False):\n",
    "    \n",
    "    compiled_model_dir = f'{model_type}_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "    inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "    shutil.rmtree(inf1_compiled_model_dir, ignore_errors=True)\n",
    "    \n",
    "    compiler_args = ['--verbose','1', '--neuroncore-pipeline-cores', str(num_cores)]\n",
    "    \n",
    "    result = tfn.saved_model.compile(\n",
    "        saved_model_dir, compiled_model_dir,\n",
    "        # to enforce trivial compilable subgraphs to run on CPU\n",
    "    #     no_fuse_ops=no_fuse_ops,\n",
    "        minimum_segment_size=100,\n",
    "        batch_size=batch_size,\n",
    "        dynamic_batch_size=True,\n",
    "        compiler_args = compiler_args\n",
    "    )\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 32 core nums 1 compile start\n",
      "INFO:tensorflow:Restoring parameters from yolo_v3_coco_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 366 variables.\n",
      "INFO:tensorflow:Converted 366 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph {subgraph neuron_op_d458f099f41f205c with input tensors [\"<tf.Tensor 'Preprocessor/map/TensorArrayStack/TensorArrayGatherV30/_0:0' shape=(32, 416, 416, 3) dtype=float16>\"], output tensors [\"<tf.Tensor 'conv_lbbox/BiasAdd:0' shape=(32, 13, 13, 255) dtype=float16>\", \"<tf.Tensor 'conv_mbbox/BiasAdd:0' shape=(32, 26, 26, 255) dtype=float16>\", \"<tf.Tensor 'conv_sbbox/BiasAdd:0' shape=(32, 52, 52, 255) dtype=float16>\", \"<tf.Tensor 'Postprocessor/map/strided_slice:0' shape=() dtype=int32>\", \"<tf.Tensor 'Postprocessor/map/TensorArrayUnstack/range:0' shape=(32,) dtype=int32>\", \"<tf.Tensor 'Postprocessor/map/TensorArrayUnstack_1/range:0' shape=(32,) dtype=int32>\", \"<tf.Tensor 'Postprocessor/map/TensorArrayUnstack_2/range:0' shape=(32,) dtype=int32>\"]} with neuron-cc; you may check progress by inspecting file /tmp/tmpk2dup4rf/neuron_op_d458f099f41f205c/graph_def.neuron-cc.log\n"
     ]
    }
   ],
   "source": [
    "inf1_model_dir = f'{model_type}_inf1_saved_models'\n",
    "saved_model_dir = f'{model_type}_saved_model'\n",
    "\n",
    "\n",
    "# testing batch size\n",
    "batch_list = [32,64]\n",
    "num_of_cores = [1]\n",
    "for batch in batch_list:\n",
    "    for core in num_of_cores:\n",
    "        print('batch size:', batch,'core nums', core,'compile start')\n",
    "        compile_inf1_model(saved_model_dir, inf1_model_dir, batch_size=batch, num_cores=core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuron_tensorflow_p36_2",
   "language": "python",
   "name": "aws_neuron_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
